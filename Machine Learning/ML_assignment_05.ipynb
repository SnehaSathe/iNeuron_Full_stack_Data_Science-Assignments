{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04be167d-c048-45da-ab6e-2bf19f700fd8",
   "metadata": {},
   "source": [
    "# Assignment No.05 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d022ad2-e208-4fd9-bea1-8c46a8e26197",
   "metadata": {},
   "source": [
    "**1. What are the key tasks that machine learning entails? What does data pre-processing imply?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a892af-f7d2-4eba-8e50-036069dc40da",
   "metadata": {},
   "source": [
    "**Ans:**  Machine learning encompasses several key tasks. Here are some of the most important ones: <br>\n",
    "\n",
    "**Classification:** Assigning data points to predefined categories.<br>\n",
    "**Clustering:** Grouping similar data points.<br>\n",
    "**Dimensionality Reduction:** Reducing features.<br>\n",
    "**Reinforcement Learning:** Sequential decision-making.<br>\n",
    "**Object Recognition:** Identifying objects in images.<br>\n",
    "**Summarization:** Extracting key information.<br>\n",
    "**Prediction:** Forecasting future outcomes.<br>\n",
    "**Recommender Systems:** Personalized recommendations.<br>\n",
    "\n",
    "Data Pre-processing refers to the steps taken to clean, transform, and prepare raw data before feeding it into a machine learning model. It’s a crucial phase because the quality of input data significantly impacts the performance of the model. model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f68abd-b3aa-45aa-bc37-109c0d4c7674",
   "metadata": {},
   "source": [
    "**2. Describe quantitative and qualitative data in depth. Make a distinction between the two.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0d108-2673-4fc9-8d54-a2b7592e7489",
   "metadata": {},
   "source": [
    "**Ans:** <br>\n",
    "**Quantitative Data:** Quantitative data refers to any information that can be quantified. If it can be counted or measured, and given a numerical value, it’s quantitative data. Quantitative data can tell you “how many,” “how much,” or “how often”—<br>\n",
    "for example, how many people attended last week’s webinar? How much revenue did the company make in 2019? How often does a certain customer group use online banking?<br>\n",
    "**Qualitative Data:** qualitative data cannot be measured or counted. It’s descriptive, expressed in terms of language rather than numerical values.<br>\n",
    "Qualitative data to answer “Why?” or “How?” questions. For example, if quantitative data tells that a certain website visitor abandoned their shopping cart three times in one week, we’d probably want to investigate why—and this might involve collecting some form of qualitative data from the user. Perhaps we want to know how a user feels about a particular product; again, qualitative data can provide such insights. In this case, we’re not just looking at numbers; we’re asking the user to tell us, using language, why they did something or how they feel.<br>\n",
    "Qualitative data also refers to the words or labels used to describe certain characteristics or traits—for example, describing the sky as blue or labeling a particular ice cream flavor as vanilla.<br><br>\n",
    "**Differences between Quantitative and Qualitative data:**<br>\n",
    "1. Quantitative data is countable or measurable, relating to numbers. Qualitative data is descriptive, relating to language.<br>\n",
    "2. Quantitative data tells us how many, how much, or how often (e.g. “20 people signed up to our email newsletter last week”). Qualitative data can help us to understand the “why” or “how” behind certain behaviors, or it can simply describe a certain attribute—for example, “The postbox is red” or “I signed up to the email newsletter because I’m really interested in hearing about local events.<br>\n",
    "3. Quantitative data is gathered by measuring and counting. Qualitative data is collected by interviewing and observing.<br>\n",
    "4. Quantitative data is analyzed using statistical analysis, while qualitative data is analyzed by grouping it in terms of meaningful categories or themes...lla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2db3c2-50b6-4645-9550-83faf6e8beb4",
   "metadata": {},
   "source": [
    "**3. Create a basic data collection that includes some sample records. Have at least one attribute from\n",
    "each of the machine learning data types.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f21e83-feb8-4ca0-9d71-95e8754dd6e5",
   "metadata": {},
   "source": [
    "**Ans:** \n",
    "## Movie Recommendation Dataset\n",
    "\n",
    "This is a basic sample dataset for movie recommendations. It includes attributes from various machine learning data types:\n",
    "\n",
    "* **Categorical:** Genre\n",
    "* **Numerical:** Release Year, Watch Time (minutes)\n",
    "* **Boolean:** Watched (Yes/No)\n",
    "\n",
    "| Title | Genre | Release Year | Watch Time (min) | Watched |\n",
    "|---|---|---|---|---|\n",
    "| The Shawshank Redemption | Drama | 1994 | 142 | Yes |\n",
    "| The Godfather | Crime | 1972 | 175 | No |\n",
    "| The Dark Knight | Action | 2008 | 152 | Yes |\n",
    "| Pulp Fiction | Crime, Comedy | 1994 | 154 | No |\n",
    "| Inception | Action, Sci-Fi | 2010 | 148 | Yes |\n",
    "\n",
    "**Data Types Explained:**\n",
    "\n",
    "* **Title:** Categorical text representing the movie name.\n",
    "* **Genre:** Categorical text representing the movie genre(s). \n",
    "* **Release Year:** Numerical data indicating the year the movie was released.\n",
    "* **Watch Time (min):** Numerical data representing the movie's duration in minutes.\n",
    "* **Watched:** Boolean value indicating if the user has watched the movie (\"Yes\" or \"No\").\n",
    "\n",
    "This is a very basic example, but it demonstrates how different data types can be combined to create a dataset suitable for machine learning tasks like movie recommendation systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2fd05-adaf-4b79-8aa0-c0db55e4d50d",
   "metadata": {},
   "source": [
    "**4. What are the various causes of machine learning data issues? What are the ramifications?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d0a60-63b4-422f-8e73-18107c0656de",
   "metadata": {},
   "source": [
    "**Ans:** Data is the lifeblood of machine learning (ML). Here are some common causes of machine learning data issues and their ramifications:<br>\n",
    "\n",
    "\r\n",
    "**1. Inaccurate or Incomplete Data:**\r\n",
    "\r\n",
    "* **Causes:** Typos, missing values, inconsistencies in data formatting.\r\n",
    "* **Ramifications:** Models can learn incorrect patterns, leading to poor predictions and biased outputs.  Imagine a spam filter trained on data with many misspelled words. It might flag legitimate emails containing typos as spam.\r\n",
    "\r\n",
    "**2. Non-representative Data:**\r\n",
    "\r\n",
    "* **Causes:** Data skewed towards a specific subset of the population, not reflecting real-world distribution.\r\n",
    "* **Ramifications:** Models perform well on the data they were trained on but fail to generalize to unseen data.  For example, an image recognition model trained only on pictures of cats might struggle to identify dogs.\r\n",
    "\r\n",
    "**3. Imbalanced Data:**\r\n",
    "\r\n",
    "* **Causes:** One class in the data has significantly more examples than others.\r\n",
    "* **Ramifications:** Models prioritize the majority class, neglecting the minority class and leading to inaccurate predictions for the underrepresented group.  An ad recommendation system trained mostly on data from young users might not perform well for recommending products to older users.\r\n",
    "\r\n",
    "**4. Biased Data:**\r\n",
    "\r\n",
    "* **Causes:** Underlying prejudices or social inequalities reflected in the data collection process.\r\n",
    "* **Ramifications:** Models perpetuate existing biases, leading to discriminatory or unfair outcomes.  An ML model used for loan approvals trained on historical data that favored certain demographics might continue that bias. \r\n",
    "\r\n",
    "**5. Outliers and Anomalies:**\r\n",
    "\r\n",
    "* **Causes:** Extreme values or data points that deviate significantly from the norm.\r\n",
    "* **Ramifications:** Outliers can skew the model's training process, leading to inaccurate predictions and a distorted understanding of the data.  Imagine training a temperature prediction model with a data point including a random scorching hot value due st and reliable ML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f72659-eda5-47a7-a025-b6655cc8e81e",
   "metadata": {},
   "source": [
    "**5. Demonstrate various approaches to categorical data exploration with appropriate examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25937648-9c94-4b94-84b6-a4f82838a920",
   "metadata": {},
   "source": [
    "**Ans:** Here are various approaches to explore categorical data, along with examples:\n",
    "\n",
    "**1. Frequency Tables and Bar Charts:**\n",
    "\n",
    "* **Description:** This is the most basic approach. It involves creating a table showing the number of occurrences (frequency) for each category within the variable. This can be visualized with bar charts for better comprehension.\n",
    "\n",
    "* **Example:** Analyzing a dataset on customer purchases, you might have a categorical variable \"Product Category\" (e.g., Clothing, Electronics, Books). A frequency table would show the count of purchases for each category. A bar chart would visually represent these counts, allowing you to see which category has the most sales.\n",
    "\n",
    "**2. Cross-Tabulation and Stacked Charts:**\n",
    "\n",
    "* **Description:** This technique explores the relationship between two categorical variables. It creates a crosstabulation table showing the frequency of each combination of categories. Stacked charts can visualize this data, where each bar is further stacked by the subcategories within the other variable.\n",
    "\n",
    "* **Example:** Continuing with the customer purchase data, you might create a crosstabulation to see how \"Product Category\" relates to \"Customer Age Group.\" The stacked chart would show the total number of purchases for each age group, further broken down by product category. This helps identify which age groups buy specific products more.\n",
    "\n",
    "**3. Percentages and Pie Charts:**\n",
    "\n",
    "* **Description:** This approach involves calculating the percentage of observations within each category. Pie charts can be used to represent these percentages visually.\n",
    "\n",
    "* **Example:**  Imagine a dataset on movie genres with a categorical variable \"Genre.\" Calculating percentages would reveal the proportion of movies belonging to each genre (e.g., 30% Comedy, 20% Action). A pie chart would visually represent these proportions, giving a quick overview of genre distribution.\n",
    "\n",
    "**4. Boxplots and Violin Plots:**\n",
    "\n",
    "* **Description:** While these visualization techniques are typically used for numerical data, they can be adapted for categorical data when paired with a numerical variable. Boxplots or violin plots can show the distribution of a numerical variable across different categories of the categorical variable.\n",
    "\n",
    "* **Example:**  Let's say you have a dataset on student grades with a categorical variable \"Course\" (e.g., Math, English, Science) and a numerical variable \"Exam Score.\" Boxplots can be created to see the distribution of exam scores for each course. This helps identify if a particular course has consistently higher or lower scores.\n",
    "\n",
    "**5. Correlation Analysis (Nominal vs. Ordinal):**\n",
    "\n",
    "* **Description:** Correlation analysis is typically used for numerical data, but it can be cautiously applied to categorical data as well.  However, the approach differs depending on the type of categorical variable:\n",
    "\n",
    "    * **Nominal Data (No inherent order):** Techniques like chi-square tests can be used to assess if there's a statistically significant relationship between two nominal variables.\n",
    "    * **Ordinal Data (Has a natural order):** Spearman's rank correlation coefficient can be used to measure the strength and direction of the relationship between an ordinal variable and another variable (numerical or ordinal).\n",
    "\n",
    "* **Example 1 (Nominal):**  In a customer survey dataset, you might have a nominal variable \"Customer Satisfaction\" (e.g., Very Satisfied, Satisfied, Neutral) and a categorical variable \"Product Type\" (e.g., Phone, Laptop, Tablet). A chi-square test could help determine if there's a significant association between customer satisfaction and product type.\n",
    "\n",
    "* **Example 2 (Ordinal):**  Continuing with the student grades example, \"Course Difficulty\" could be a categorical variable with ordinal levels (e.g., Easy, Medium, Hard). Spearman's rank correlation can be used to see if there's a correlation between course difficulty and exam scores (numerical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d1afc-159f-40d7-afc2-a0aec869ea76",
   "metadata": {},
   "source": [
    "**6. How would the learning activity be affected if certain variables have missing values? Having said\n",
    "that, what can be done about it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f9bb4-296e-4cbb-8922-33662a02fdf7",
   "metadata": {},
   "source": [
    "**Ans:** Missing values in your data can significantly impact the learning activity of a machine learning model.<br>\n",
    "\n",
    "**Negative Effects of Missing Values:**\n",
    "\n",
    "* **Reduced Accuracy and Generalizability:** Models trained on incomplete data might not learn the underlying patterns accurately. This can lead to poor predictions on new data, especially if the missing values are not random.\n",
    "* **Biased Results:**  If data is missing systematically (e.g., income data missing for low-income individuals), the model might learn biased patterns that don't reflect reality.\n",
    "* **Limited Statistical Techniques:** Some statistical methods and algorithms require complete data for all variables. Missing values can restrict the types of analyses you can perform.\n",
    "* **Increased Training Time:** Depending on the chosen method for handling missing values, it can add an extra step to the data preprocessing stage, increasing training time.\n",
    "\n",
    "**Approaches to Handling Missing Values:**\n",
    "\n",
    "There are several techniques to address missing values, each with its own advantages and limitations. The best approach depends on the specific data and the machine learning model being used. Here are some common methods:\n",
    "\n",
    "1. **Deletion:** \n",
    "2. **Imputation:** \n",
    "    * **Mean/Median/Mode imputation:** \n",
    "    * **K-Nearest Neighbors (KNN):**\n",
    "    * **Model-based imputation:**\n",
    "\n",
    "3. **Encoding Missing Values as a Separate Category:**  \n",
    "\n",
    "**Choosing the Right Approach:**\n",
    "\n",
    "The best way to handle missing values depends on several factors:\n",
    "\n",
    "* **The amount of missing data:**  For small amounts, deletion might be acceptable.  For larger amounts, imputation is often preferred.\n",
    "* **The nature of the missing data:** Are the missing values random or systematic?  Some imputation methods work better for random missingness.\n",
    "* **The type of data:**  Numerical data can be imputed with different techniques than categorical data.\n",
    "* **The machine learning model:**  Some models are more sensitive to missing values than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347dfe6-0dac-4608-8c33-f58ded153272",
   "metadata": {},
   "source": [
    "**7. Describe the various methods for dealing with missing data values in depth.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8a69d-85e2-4437-a310-87ef2b2be38c",
   "metadata": {},
   "source": [
    "**Ans:** **Approaches to Handling Missing Values:**\n",
    "\n",
    "There are several techniques to address missing values, each with its own advantages and limitations. The best approach depends on the specific data and the machine learning model being used. Here are some common methods:\n",
    "\n",
    "1. **Deletion:** This involves removing entire rows or columns with missing values.  This is a simple approach but can be wasteful if the data is limited or the missing values are not random.\n",
    "\n",
    "2. **Imputation:** This involves estimating the missing values by filling them in with a statistical method. Here are some imputation techniques:\n",
    "\n",
    "    * **Mean/Median/Mode imputation:** Replace missing values with the average (mean), middle value (median), or most frequent value (mode) for that variable. \n",
    "    * **K-Nearest Neighbors (KNN):** Use the values of similar data points to estimate the missing value.\n",
    "    * **Model-based imputation:** Train a separate model to predict the missing values based on other variables in the dataset.\n",
    "\n",
    "3. **Encoding Missing Values as a Separate Category:**  This approach creates a new category within the categorical variable specifically for missing values. This can be useful if the missingness itself holds meaning (e.g., \"income not reported\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51f10b-a65f-44dd-97bd-5ab2e7d95f85",
   "metadata": {},
   "source": [
    "**8. What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
    "function selection in a few words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e0927-51cb-46e5-afa4-df1e9b17803c",
   "metadata": {},
   "source": [
    "**Ans:** Data preprocessing is like getting your ingredients ready before you cook a meal. It prepares your data for a machine learning model by transforming it into a usable format. Here are some common techniques:<br>\n",
    "\n",
    "**1. Data Cleaning:**\n",
    "\n",
    "* Fixing errors and inconsistencies in your data, like typos or missing values (we discussed this in detail earlier!).\n",
    "* Removing outliers (extreme values) that might skew your model.\n",
    "\n",
    "**2. Data Transformation:**\n",
    "\n",
    "* Scaling numerical features to a common range for better comparison.\n",
    "* Encoding categorical variables into numerical representations that models can understand.\n",
    "\n",
    "**3. Data Integration:**\n",
    "\n",
    "* Combining data from different sources into a single dataset, ensuring consistency in formatting and meaning.\n",
    "\n",
    "**4. Data Reduction:**\n",
    "\n",
    "* **Dimensionality Reduction:** This tackles datasets with many features (dimensions). Techniques like Principal Component Analysis (PCA) can reduce the number of features while preserving most of the information. Imagine reducing a complex recipe with many ingredients to a simpler, more focused version while keeping the core flavors.\n",
    "\n",
    "**5. Feature Selection:**\n",
    "\n",
    "* Choosing the most relevant features from your dataset for your specific machine learning task. This can improve model performance and reduce training time. Think of selecting only the key ingredients crucial for your dish, instead of using everything in the pantry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c44172-5425-4ab7-8d61-abca86bf1491",
   "metadata": {},
   "source": [
    "**9.i. What is the IQR? What criteria are used to assess it?<br>\n",
    "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
    "surpass the upper whisker in length? How can box plots be used to identify outliers?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2bf48-bf5c-43e1-bfe5-d9af1b2f3385",
   "metadata": {},
   "source": [
    "**Ans:** ## Demystifying Boxplots and IQR\n",
    "\n",
    "i. **The Interquartile Range (IQR):** \n",
    "\n",
    "The IQR is a measure of spread or variability within a dataset. It focuses on the middle 50% of the data, excluding potential outliers. Here's how we assess it:\n",
    "\n",
    "1. **Calculate the Quartiles:**\n",
    "    * Find the median (Q2): the middle value when the data is ordered from least to greatest.\n",
    "    * Find the first quartile (Q1): the median of the lower half of the data.\n",
    "    * Find the third quartile (Q3): the median of the upper half of the data.\n",
    "\n",
    "2. **Calculate the IQR:** IQR = Q3 - Q1\n",
    "\n",
    "**Criteria for Assessing IQR:**\n",
    "\n",
    "* A larger IQR indicates a greater spread of data within the middle 50%.\n",
    "* A smaller IQR indicates the data points are clustered closer to the median.\n",
    "\n",
    "\n",
    "ii. **Unpacking the Box Plot:**\n",
    "\n",
    "A box plot is a visual representation of the IQR and other key statistics of a dataset. Here's a breakdown of its components:\n",
    "\n",
    "* **Box:** Represents the IQR. The bottom of the box is at Q1, and the top is at Q3.\n",
    "* **Median:** A line inside the box that divides it into two halves, representing the middle value of the data.\n",
    "* **Whiskers:** Lines extending from the box. The upper whisker extends from Q3 to the largest data point within 1.5 times the IQR above Q3. The lower whisker extends from Q1 to the smallest data point within 1.5 times the IQR below Q1.\n",
    "* **Outliers:** Data points that fall outside the whisker range are considered potential outliers and are typically plotted as individual points.\n",
    "\n",
    "**Lower Whisker Surpassing Upper Whisker (Usually Doesn't Happen):**\n",
    "\n",
    "In a typical box plot, the lower whisker won't be longer than the upper whisker. This is because the IQR represents the middle 50% of the data, and the whiskers capture data points within 1.5 IQRs from the quartiles. It's very unlikely for the minimum value to be further from Q1 than the maximum value is from Q3.\n",
    "\n",
    "However, in rare cases with skewed data distributions, it's mathematically possible for the lower whisker to extend slightly further than the upper whisker. This would indicate a very asymmetrical distribution with a longer tail towards the lower end. \n",
    "\n",
    "**Identifying Outliers with Box Plots:**\n",
    "\n",
    "Box plots are a great tool for spotting potential outliers. Any data points that fall outside the whisker range (beyond 1.5 times the IQR from the quartiles) are suspect. These points might represent errors, anomalies, or extreme values that could skew your analysis. Analyzing these outliers is crucial to understand if they are genuine or need further investigation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37803d31-4042-4315-bf30-5417832d980e",
   "metadata": {},
   "source": [
    "**10. Make brief notes on any two of the following:<br> 1. Data collected at regular intervals<br>\n",
    "2. The gap between the quartiles<br>\n",
    "3. Use a cross-tab**<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1361a-127b-4baf-9f6f-fd356ed2ebd7",
   "metadata": {},
   "source": [
    "**1. Data collected at regular intervals**<br>\n",
    "Data collected at regular intervals is called **time series data**. It refers to any information that's measured or recorded over time at consistent intervals. These intervals can vary widely, from seconds (stock prices) to months (customer churn rate) or even years (global temperatures).\n",
    "\n",
    "Here are some key aspects of time series data:\n",
    "\n",
    "* **Ordered:** The data points have a specific order based on the time they were collected. This order is crucial for analysis.\n",
    "* **Regular Intervals:** The data is collected at consistent time frames, such as hourly, daily, weekly, monthly, etc.\n",
    "* **Dependence:** Often, data points in a time series are dependent on each other. For example, today's temperature might be influenced by yesterday's temperature.\n",
    "\n",
    "**Examples of Time Series Data:**\n",
    "\n",
    "* **Finance:** Stock prices, exchange rates, trading volume (recorded every second or minute).\n",
    "* **Website Analytics:** Website traffic, user behavior, page views (recorded hourly, daily).\n",
    "* **Sensor Data:** Temperature, humidity, pressure readings (recorded every few seconds or minutes).\n",
    "\n",
    "**Machine learning models** are particularly adept at analyzing time series data. Techniques like ARIMA (Autoregressive Integrated Moving Average) and LSTMs (Long Short-Term Memory) can learn from historical patterns and make accurate predictions about future trends. \n",
    "\n",
    "**2. The gap between the quartiles**<br>\n",
    "The gap between the quartiles in a dataset is precisely what the **Interquartile Range (IQR)** represents. <br>\n",
    "\n",
    "\n",
    "* **Quartiles:** These are the three values that divide the data into four equal parts when ordered from least to greatest.\n",
    "    * Q1 (First Quartile): The median of the lower half of the data.\n",
    "    * Q2 (Median): The middle value of the entire data set.\n",
    "    * Q3 (Third Quartile): The median of the upper half of the data.\n",
    "\n",
    "* **Interquartile Range (IQR):**  This statistic is calculated as:\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "Therefore, the IQR represents the range that covers the middle 50% of the data points, essentially depicting the \"spread\" within the central portion of your dataset. It's a robust measure of variability that is less sensitive to outliers compared to the full range (maximum value - minimum value).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60c44e-22fb-487a-b388-821d987b2fb5",
   "metadata": {},
   "source": [
    "**10.1. Make a comparison between:<br>1. Data with nominal and ordinal values<br>\n",
    "2. Histogram and box plot<br>\n",
    "3. The average and median**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8197be-0b03-4745-9ed4-a6d27b629a32",
   "metadata": {},
   "source": [
    "**Ans:**<br>\n",
    "**1.Data with nominal and ordinal values**<br>\n",
    "The main distinction between nominal and ordinal data lies in their inherent order.\n",
    "\n",
    "**Nominal data:** Represents categories with no inherent order or ranking. The order in which they are listed is arbitrary.  For example, shirt color (red, blue, green) doesn't imply any hierarchy.  Blue isn't \"better\" than red, they are simply different color options.\n",
    "\n",
    "**Ordinal data:** Represents categories with a natural order or ranking. There's a clear progression from one category to the next.  For example, customer satisfaction (very satisfied, satisfied, neutral, dissatisfied) follows a clear order of decreasing satisfaction.<br>\n",
    "\n",
    "**2. Histogram and box plot**<br>\n",
    "\n",
    "**Histogram:** Purpose of histogram is to Visualize distribution of data.See the overall shape of the distribution, including potential gaps, clusters, and the frequency of values within certain ranges, a histogram is a good choice.\t<br>\n",
    "**Box plot:** Purpose of Box plot is to Summarize key statistics (IQR, median, outliers). Focus on summarizing key statistics like the median (center), spread (IQR), and presence of outliers, a box plot is ideal. It provides a compact way to represent these aspects of the data.<br>\n",
    "\n",
    "**3. The average and median**<br>\n",
    "\n",
    "**Average:** The average is simple to calculate and widely understood. However, it can be easily skewed by outliers. If you have a few very high or low values, the average might not be a good representation of the typical data point.<br>\n",
    "\n",
    "**Median:** The median is not affected by outliers as much as the average. It gives a more accurate picture of the \"middle\" value, especially in datasets with skewed distributions or outliers. However, the median doesn't capture the entire spread of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319c099-4bec-4ffd-b778-42c79686a3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
